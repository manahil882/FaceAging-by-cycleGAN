{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manahil882/FaceAging-by-cycleGAN/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id"
      },
      "source": [
        "import os\n",
        "\n",
        "import anthropic\n",
        "import google.generativeai as genai\n",
        "from llamaapi import LlamaAPI\n",
        "from openai import OpenAI"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Input and Output path\n",
        "file_path = 'input.txt'\n",
        "input_menus_dir = 'input/'"
      ],
      "metadata": {
        "id": "8edc3ba8c99c7df1"
      },
      "id": "8edc3ba8c99c7df1",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "6c0e05fef8e6966e"
      },
      "cell_type": "code",
      "source": [
        "# Set your OpenAI API key\n",
        "OPENAI_API_KEY = \"sk-1234qrstuvwxabcd1234qrstuvwxabcd1234qrst\"\n",
        "GEMINI_API_KEY = \"AIzaSyBrIDrlfCMNNzXuUkZUYnr5LOkeiTIWKXQ\"\n",
        "LLAMA_API_KEY = \"63eb5d09-bd16-48b0-88f5-21d89fc41374\"\n",
        "ANTHROPIC_API_KEY = \"KEY\""
      ],
      "id": "6c0e05fef8e6966e",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "1cafebf6fc8d915c"
      },
      "cell_type": "code",
      "source": [
        "# Set your models\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "llama_client = LlamaAPI(LLAMA_API_KEY)\n",
        "anthropic_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)"
      ],
      "id": "1cafebf6fc8d915c",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "c9f323956002404d"
      },
      "cell_type": "code",
      "source": [
        "# Define the template prompt as a global parameter\n",
        "TEMPLATE_PROMPT = \"\"\"\n",
        "User preferences are: {user_preferences}.\n",
        "User restrictions are: {user_restrictions}.\n",
        "User's goal is to create a meal plan that meets the following targets:\n",
        "- Total daily calories: {total_calories} kcal.\n",
        "- Total daily protein: {target_protein}g.\n",
        "- Total daily sugar: {target_sugar}g.\n",
        "The plan must include:\n",
        "- Breakfast, lunch, dinner, and snacks.\n",
        "- The calorie count for each meal (e.g., \"Breakfast: 400 kcal\").\n",
        "- At the end of each meal plan option, provide the total calories, total fat, total protein, and total carbohydrate.\n",
        "- For each item in the meal plans (e.g., breakfast, lunch), specify the exact portion sizes, including the number of items or volume (e.g., \"1 Kit Kat bar (45g),\" \"1 hamburger with a 150g beef patty, bun, and lettuce\").\n",
        "- Provide a short recipe for each item in the meal plan, detailing how it can be prepared (e.g., \"Grill the patty for 5 minutes, then assemble with lettuce, tomato, and a bun\").\n",
        "Provide three different meal plan options for diversity.\n",
        "Use familiar dishes instead of listing individual food items. For example, use \"hamburger\" instead of \"150 grams of meat with bun and lettuce.\"\n",
        "Ensure the plan adheres to the user's preferences and restrictions and meets the specified targets while maintaining a balanced nutritional profile.\n",
        "Here is the available items for generating the meal plan:\n",
        "{menu_input}\n",
        "\"\"\""
      ],
      "id": "c9f323956002404d",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "386dbcbaf5a7fd9"
      },
      "cell_type": "code",
      "source": [
        "def process_menus(input_dir, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    menus = []\n",
        "    with open(input_dir, 'r') as file:\n",
        "        content = file.read()\n",
        "        # Split menus by separators (---)\n",
        "        menu_sections = content.strip().split('---')\n",
        "\n",
        "        for idx, section in enumerate(menu_sections):\n",
        "            lines = section.strip().split('\\n')\n",
        "            menu = {\"foods\": {}, \"energy\": None, \"protein\": None, \"sugar\": None}\n",
        "\n",
        "            # Process each line in the menu section\n",
        "            for line in lines:\n",
        "                if line.startswith(\"Food_\"):\n",
        "                    # Parse food items and their quantities\n",
        "                    food, quantity = line.split('=')\n",
        "                    menu[\"foods\"][food.strip()] = float(quantity.strip())\n",
        "                elif line.startswith(\"energy\"):\n",
        "                    # Parse energy value\n",
        "                    menu[\"energy\"] = float(line.split()[1])\n",
        "                elif line.startswith(\"protein\"):\n",
        "                    # Parse protein value\n",
        "                    menu[\"protein\"] = float(line.split()[1])\n",
        "                elif line.startswith(\"sugar\"):\n",
        "                    # Parse sugar value\n",
        "                    menu[\"sugar\"] = float(line.split()[1])\n",
        "\n",
        "            # Add the menu to the list\n",
        "            menus.append(menu)\n",
        "\n",
        "            # Save the menu to a separate text file\n",
        "            menu_file_path = os.path.join(output_dir, f\"menu_{idx + 1}.txt\")\n",
        "            with open(menu_file_path, \"w\", encoding=\"utf-8\") as menu_file:\n",
        "                # Write the foods\n",
        "                for food, quantity in menu[\"foods\"].items():\n",
        "                    menu_file.write(f\"{food} = {quantity}\\n\")\n",
        "                # Write the nutritional values\n",
        "                menu_file.write(\"--------------------------\\n\")\n",
        "                menu_file.write(f\"energy = {menu['energy']}\\n\")\n",
        "                menu_file.write(f\"protein = {menu['protein']}\\n\")\n",
        "                menu_file.write(f\"sugar = {menu['sugar']}\\n\")\n",
        "\n",
        "    return menus"
      ],
      "id": "386dbcbaf5a7fd9",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "4b59cdf04dc65c98"
      },
      "cell_type": "code",
      "source": [
        "def generate_prompts_from_menus(menus, user_preferences=\"\", user_restrictions=\"\"):\n",
        "    prompts = []\n",
        "\n",
        "    for menu in menus:\n",
        "        # Format the menu items into a string\n",
        "        menu_input = \"\\n\".join([f\"{food} = {quantity}\" for food, quantity in menu['foods'].items()])\n",
        "\n",
        "        # Fill the template with data from the menu\n",
        "        prompt = TEMPLATE_PROMPT.format(\n",
        "            user_preferences=user_preferences,\n",
        "            user_restrictions=user_restrictions,\n",
        "            total_calories=menu['energy'],\n",
        "            target_protein=menu['protein'],\n",
        "            target_sugar=menu['sugar'],\n",
        "            menu_input=menu_input\n",
        "        )\n",
        "\n",
        "        prompts.append(prompt.strip())\n",
        "\n",
        "    return prompts"
      ],
      "id": "4b59cdf04dc65c98",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "26b60798c4babf2d"
      },
      "cell_type": "code",
      "source": [
        "def call_llm_api(prompts, company, model_name, max_tokens=2000, temperature=0.7):\n",
        "    responses = []\n",
        "\n",
        "    for i, prompt in enumerate(prompts):\n",
        "        print(f\"Processing prompt {i + 1} of {len(prompts)}...\")\n",
        "\n",
        "        try:\n",
        "            if company == \"openai\":\n",
        "                response = openai_client.chat.completions.create(\n",
        "                    model=model_name,\n",
        "                    messages=[\n",
        "                        {\"role\": \"user\", \"content\": prompt},\n",
        "                    ],\n",
        "                    max_tokens=max_tokens,\n",
        "                    temperature=temperature,\n",
        "                )\n",
        "                meal_plan = response.choices[0].message.content\n",
        "                responses.append(meal_plan)\n",
        "\n",
        "            elif company == \"google\":\n",
        "                model = genai.GenerativeModel(model_name)\n",
        "                response = model.generate_content(prompt)\n",
        "                responses.append(response)\n",
        "\n",
        "            elif company == \"meta\":\n",
        "                api_request_json = {\"model\": model_name, \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "                                    \"max_tokens\": max_tokens, \"temperature\": temperature, }\n",
        "                response = llama_client.run(api_request_json)\n",
        "                content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "                responses.append(content)\n",
        "\n",
        "            elif company == \"anthropic\":\n",
        "                message = anthropic_client.messages.create(model=model_name, max_tokens=max_tokens, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
        "                content = message.content[0].text\n",
        "                responses.append(content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing prompt {i + 1}: {e}\")\n",
        "            responses.append(f\"Error: {e}\")\n",
        "\n",
        "    return responses"
      ],
      "id": "26b60798c4babf2d",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "7ac4efa5574d8064"
      },
      "cell_type": "code",
      "source": [
        "menus = process_menus(input_dir=file_path, output_dir=input_menus_dir)"
      ],
      "id": "7ac4efa5574d8064",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "64e931ce9b0084ac"
      },
      "cell_type": "code",
      "source": [
        "prompts = generate_prompts_from_menus(menus)"
      ],
      "id": "64e931ce9b0084ac",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "f4f8ba060ababb3d"
      },
      "cell_type": "code",
      "source": [
        "model_name=\"gpt-4o\"\n",
        "company=\"openai\"\n",
        "responses = call_llm_api(prompts=prompts, company=company, model_name=model_name)"
      ],
      "id": "f4f8ba060ababb3d",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "28c762992dfccd49"
      },
      "cell_type": "code",
      "source": [
        "# Save each response to a file\n",
        "out_dir = f\"output_{model_name}\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "for i, response in enumerate(responses):\n",
        "    with open(out_dir + f\"/response_{i + 1}.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(response)\n",
        "    print(f\"Saved response {i + 1} to \" + out_dir + f\"/response_{i + 1}.txt\")"
      ],
      "id": "28c762992dfccd49",
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}